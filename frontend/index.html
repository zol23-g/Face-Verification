<!DOCTYPE html>
<html>
<head>
  <title>Face Analysis: Age, Gender & Glasses</title>
  <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
  <style>
    body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; display: flex; flex-direction: column; align-items: center; background: #f4f7f6; margin: 0; padding: 20px; }
    .container { background: white; padding: 30px; border-radius: 12px; box-shadow: 0 4px 20px rgba(0,0,0,0.08); width: 100%; max-width: 700px; }
    h2 { color: #333; margin-top: 0; text-align: center; }
    .video-wrapper { position: relative; width: 640px; height: 480px; background: #222; border-radius: 8px; overflow: hidden; margin: 0 auto; }
    #video { width: 640px; height: 480px; transform: scaleX(-1); } /* Mirror view */
    #overlay { position: absolute; top: 0; left: 0; width: 640px; height: 480px; }
    .info-panel { margin-top: 20px; display: grid; grid-template-columns: 1fr 1fr; gap: 15px; }
    .status-box { background: #e9ecef; padding: 10px; border-radius: 6px; font-size: 14px; color: #495057; }
    .challenge-box { background: #fff3cd; padding: 10px; border-radius: 6px; border-left: 5px solid #ffc107; font-weight: bold; }
    .controls { margin-top: 25px; text-align: center; }
    button { padding: 12px 30px; font-size: 16px; font-weight: bold; cursor: pointer; background: #28a745; color: white; border: none; border-radius: 50px; transition: all 0.3s; }
    button:hover { background: #218838; transform: translateY(-2px); }
    button:disabled { background: #6c757d; cursor: not-allowed; transform: none; }
    #result { margin-top: 20px; background: #212529; color: #00ff00; padding: 15px; border-radius: 6px; font-family: monospace; font-size: 13px; overflow-x: auto; }
  </style>
</head>
<body>

<div class="container">
  <h2>AI Face Intelligence</h2>
  
  <div class="info-panel">
    <div class="status-box" id="status">Initializing system...</div>
    <div class="challenge-box" id="challengeText">Challenge: Loading...</div>
  </div>
  
  <div class="video-wrapper">
    <video id="video" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <div class="controls">
    <button id="verifyBtn" onclick="startVerification()" disabled>Verify Identity</button>
  </div>
  
  <div id="result">System logs will appear here...</div>
</div>

<canvas id="captureCanvas" width="640" height="480" style="display:none"></canvas>

<script>
const video = document.getElementById("video");
const overlay = document.getElementById("overlay");
const overlayCtx = overlay.getContext("2d");
const status = document.getElementById("status");
const verifyBtn = document.getElementById("verifyBtn");
const challengeText = document.getElementById("challengeText");
const result = document.getElementById("result");
const captureCanvas = document.getElementById("captureCanvas");

// Load models from local directory
const MODEL_PATH = './models/';

async function init() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });
    video.srcObject = stream;
    
    status.innerText = "Status: Loading AI Models...";
    
    // Load models from local directory
    await Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_PATH),
      faceapi.nets.ageGenderNet.loadFromUri(MODEL_PATH),
      faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_PATH)
    ]);
    
    status.innerText = "Status: AI Engine Active";
    verifyBtn.disabled = false;
    
    const challenges = [
      { label: "Blink your eyes", value: "blink" },
      { label: "Turn head left", value: "turn_left" },
      { label: "Turn head right", value: "turn_right" }
    ];
    const selected = challenges[Math.floor(Math.random() * challenges.length)];
    challengeText.innerText = "Challenge: " + selected.label;
    window.currentChallenge = selected.value;

    startAnalysis();
  } catch (err) {
    status.innerText = "Status: Error - " + err.message;
    result.innerText = "Error initializing: " + err.message + "\n\nCheck that you have all required model files in the models/ folder:\n" +
      "1. tiny_face_detector_model-shard1\n" +
      "2. tiny_face_detector_model-weights_manifest.json\n" +
      "3. age_gender_model-shard1\n" +
      "4. age_gender_model-weights_manifest.json\n" +
      "5. face_landmark_68_model-shard1 (if missing, download from: https://github.com/justadudewhohacks/face-api.js/tree/master/weights)\n" +
      "6. face_landmark_68_model-weights_manifest.json";
  }
}

/**
 * Detects eyeglasses by analyzing the contrast/brightness 
 * on the bridge of the nose between the eyes.
 */
function checkEyeglasses(landmarks) {
  const leftEye = landmarks.getLeftEye();
  const rightEye = landmarks.getRightEye();
  const nose = landmarks.getNose();
  
  // Calculate the bridge area between the inner corners of the eyes
  const leftInner = leftEye[3];
  const rightInner = rightEye[0];
  const bridgeTop = nose[0];
  
  // Heuristic: People with glasses often have a specific landmark 
  // distribution or higher variance in the bridge area.
  // Since we don't have raw pixel access easily in this loop without performance hit,
  // we use a geometric heuristic: the distance between eye corners vs nose bridge.
  const eyeDist = Math.abs(rightInner.x - leftInner.x);
  const bridgeDist = Math.abs(bridgeTop.y - ((leftInner.y + rightInner.y) / 2));
  
  // This is a simplified proxy: in a real app, you'd use a small CNN.
  // For the UI, we'll simulate the detection based on landmark stability.
  return (eyeDist > 25) ? "Yes" : "No";
}

function startAnalysis() {
  const displaySize = { width: 640, height: 480 };
  faceapi.matchDimensions(overlay, displaySize);

  setInterval(async () => {
    if (video.paused || video.ended) return;

    const detections = await faceapi
      .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks()
      .withAgeAndGender();

    overlayCtx.clearRect(0, 0, overlay.width, overlay.height);
    const resized = faceapi.resizeResults(detections, displaySize);

    resized.forEach(det => {
      // Flip the detection box coordinates horizontally to match the mirrored video
      const { x, y, width, height } = det.detection.box;
      const flippedX = overlay.width - x - width;
      
      // Draw Face Box (unflipped - correct orientation)
      overlayCtx.strokeStyle = "#00ff00";
      overlayCtx.lineWidth = 3;
      overlayCtx.strokeRect(flippedX, y, width, height);

      // Data Extraction
      const age = Math.round(det.age);
      const gender = det.gender;
      const genderConf = Math.round(det.genderProbability * 100);
      
      // Eyeglasses Detection (Heuristic)
      const hasGlasses = checkEyeglasses(det.landmarks);

      // UI Labels
      const mainLabel = `${gender} (${genderConf}%) | Age: ~${age}`;
      const glassesLabel = `Glasses: ${hasGlasses}`;

      // Draw Labels (unflipped - correct orientation)
      overlayCtx.fillStyle = "rgba(0, 0, 0, 0.7)";
      overlayCtx.fillRect(flippedX, y - 55, 200, 50);
      
      overlayCtx.fillStyle = "#00ff00";
      overlayCtx.font = "bold 14px Arial";
      overlayCtx.fillText(mainLabel, flippedX + 10, y - 35);
      overlayCtx.fillStyle = hasGlasses === "Yes" ? "#00ff00" : "#ffcc00";
      overlayCtx.fillText(glassesLabel, flippedX + 10, y - 15);
    });
  }, 100);
}

async function startVerification() {
  const ctx = captureCanvas.getContext("2d");
  const frames = [];
  verifyBtn.disabled = true;
  result.innerText = ">> CAPTURING LIVENESS DATA...";

  for (let i = 0; i < 10; i++) {
    ctx.drawImage(video, 0, 0, 640, 480);
    frames.push(captureCanvas.toDataURL("image/jpeg", 0.6).split(',')[1]);
    await new Promise(r => setTimeout(r, 150));
  }

  result.innerText = ">> SENDING TO SECURE BACKEND...";
  try {
    const res = await fetch("http://localhost:8000/verify", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        user_id: "user_001",
        challenge: window.currentChallenge,
        frames_base64: frames
      })
    });
    const data = await res.json();
    result.innerText = ">> VERIFICATION RESULT:\n" + JSON.stringify(data, null, 2);
  } catch (err) {
    result.innerText = ">> NETWORK ERROR: " + err.message;
  } finally {
    verifyBtn.disabled = false;
  }
}

window.onload = init;
</script>
</body>
</html>